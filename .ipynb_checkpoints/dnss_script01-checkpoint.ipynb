{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract country profiles form DNSS application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load necessary python libraries and define working directory\n",
    "\n",
    "This script will heavily rely on the data transformation and data management methods available from the `pandas` python library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\L.GonzalezMorales\\Documents\\GitHub\\FOC-FPOS\n",
      "data inputs dir: ../data/\n",
      "outputs dir: ../output/\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib3\n",
    "http = urllib3.PoolManager()\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import os \n",
    "import hashlib\n",
    "\n",
    "import time\n",
    "\n",
    "import datetime\n",
    "\n",
    "dir_path = os.path.dirname(os.path.realpath('__file__'))\n",
    "print(dir_path)\n",
    "\n",
    "data_dir = r'../data/'\n",
    "print('data inputs dir: ' + data_dir)\n",
    "\n",
    "output_dir = r'../output/'\n",
    "print('outputs dir: ' + output_dir)\n",
    "\n",
    "\n",
    "# https://volderette.de/jupyter-notebook-tip-multiple-outputs/\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Disable insecure request warnings when using `urllib3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute a hash of a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_hash(d):\n",
    "    out = hashlib.md5()\n",
    "    for key, value in d.items():\n",
    "        out.update(key.encode('utf-8'))\n",
    "        out.update(str(value).encode('utf-8'))\n",
    "    return out.hexdigest()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get unique dictionaries in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_dicts(dictionary_list):\n",
    "\n",
    "    uniques_map = {}\n",
    "\n",
    "    for d in dictionary_list:\n",
    "        uniques_map[dict_hash(d)] = d\n",
    "\n",
    "    return list(uniques_map.values())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract subset of key-value pairs from Python dictionary object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subdict_list(dict_list, keys_list, exclude = False):\n",
    "    sub_d_list = []\n",
    "    if exclude:\n",
    "        for d in dict_list:\n",
    "            sub_d= {k: d[k] for k in d.keys() if k not in keys_list}\n",
    "            sub_d_list.append(sub_d)\n",
    "    else:\n",
    "        for d in dict_list:\n",
    "            sub_d= {k: d[k] for k in keys_list}\n",
    "            sub_d_list.append(sub_d)\n",
    "    \n",
    "    return sub_d_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get a dict from a list based on something inside the dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_dict(dict_list, k, v):\n",
    "    selected = []\n",
    "    for d in dict_list:\n",
    "        if d[k] == v:\n",
    "            selected.append(d)\n",
    "    return selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read list of country profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'DocumentNo': 7,\n",
       "  'Country': 'Albania',\n",
       "  'LastModified': Timestamp('2009-02-06 00:00:00'),\n",
       "  'DocumentLink': 'https://unstats.un.org/unsd/dnss/docViewer.aspx?docID=563'},\n",
       " {'DocumentNo': 11,\n",
       "  'Country': 'Algeria',\n",
       "  'LastModified': Timestamp('2009-09-06 00:00:00'),\n",
       "  'DocumentLink': 'https://unstats.un.org/unsd/dnss/docViewer.aspx?docID=564'},\n",
       " {'DocumentNo': 25,\n",
       "  'Country': 'Andorra',\n",
       "  'LastModified': Timestamp('2011-10-11 00:00:00'),\n",
       "  'DocumentLink': 'https://unstats.un.org/unsd/dnss/docViewer.aspx?docID=558'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xls = pd.ExcelFile('All documents.xlsx')\n",
    "x = pd.read_excel(xls, 'Country Profiles').to_dict('index')\n",
    "country_profiles = []\n",
    "for d in x:\n",
    "    country_profiles.append(x[d])\n",
    "\n",
    "country_profiles[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc(url):\n",
    "    response = http.request('GET', url)\n",
    "    doc = BeautifulSoup(response.data)\n",
    "    for br in doc.find_all(\"br\"):\n",
    "        br.replace_with(\"\\n\")\n",
    "    return doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_groups(doc):\n",
    "    groups = doc.find_all('div', {'class': ['catGroupPanel']})\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_groups(groups):\n",
    "    \n",
    "    content = []\n",
    "    \n",
    "    for g in groups:\n",
    "\n",
    "        g_dict = {}\n",
    "\n",
    "        title = g.find_all('div', {'class': ['catGroupTitle']})\n",
    "        for t in title:\n",
    "            title_text = t.text\n",
    "            #title_text\n",
    "\n",
    "        subtitles = g.find_all('div', {\"class\": ['docTitlePanel']})\n",
    "        subtitles_text = []\n",
    "        for s in subtitles:\n",
    "            subtitles_text.append(s.text)\n",
    "        #subtitles_text\n",
    "\n",
    "\n",
    "        subtitles_detail = g.find_all('div', {\"class\": None})\n",
    "        subtitles_detail_text = []\n",
    "        for sd in subtitles_detail:\n",
    "            subtitles_detail_text.append(sd.text)\n",
    "        #subtitles_detail_text\n",
    "\n",
    "        g_dict['title'] = title_text\n",
    "        g_dict['content'] = {}\n",
    "        for i in range(len(subtitles)):\n",
    "            g_dict['content'][subtitles_text[i]]= subtitles_detail_text[i]\n",
    "            \n",
    "        content.append(g_dict)\n",
    "    \n",
    "    return(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://unstats.un.org/unsd/dnss/docViewer.aspx?docID=562'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = country_profiles[0]['DocumentLink']\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc = get_doc(url)\n",
    "#groups = get_groups(doc)\n",
    "#doc_content = parse_groups(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CountryProfiles1 = []\n",
    "\n",
    "\n",
    "for cp in country_profiles[0:80]:\n",
    "    cp_dict = {}\n",
    "    cp_dict['Country'] = cp['Country']\n",
    "    cp_dict['LastModified'] = cp['LastModified']\n",
    "    cp_dict['url'] = cp['DocumentLink']\n",
    "    cp_dict['Content'] = parse_groups(get_groups(get_doc(cp['DocumentLink'])))\n",
    "    print(cp_dict['Country'])\n",
    "    \n",
    "    CountryProfiles1.append(cp_dict)\n",
    "    \n",
    "    time.sleep(0.5)\n",
    "    \n",
    "print('-----finished first block---')\n",
    "\n",
    "for i in CountryProfiles1:\n",
    "    i['LastModified'] = i['LastModified'].strftime('%d/%m/%Y')\n",
    "    \n",
    "with open('CountryProfiles1.json', 'w') as fout:\n",
    "    json.dump(CountryProfiles1, fout, indent = 4)\n",
    "    \n",
    "#wait 20 minutes\n",
    "time.sleep(1200) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CountryProfiles2 = []\n",
    "\n",
    "for cp in country_profiles[80:160]:\n",
    "    cp_dict = {}\n",
    "    cp_dict['Country'] = cp['Country']\n",
    "    cp_dict['LastModified'] = cp['LastModified']\n",
    "    cp_dict['url'] = cp['DocumentLink']\n",
    "    cp_dict['Content'] = parse_groups(get_groups(get_doc(cp['DocumentLink'])))\n",
    "    print(cp_dict['Country'])\n",
    "    print('lenght:', len(cp_dict['Content']))\n",
    "    \n",
    "    CountryProfiles2.append(cp_dict)\n",
    "    \n",
    "    time.sleep(0.5)\n",
    "    \n",
    "print('-----finished second block---')\n",
    "\n",
    "for i in CountryProfiles2:\n",
    "    i['LastModified'] = i['LastModified'].strftime('%d/%m/%Y')\n",
    "    \n",
    "with open('CountryProfiles1.json', 'w') as fout:\n",
    "    json.dump(CountryProfiles2, fout, indent = 4)\n",
    "    \n",
    "#wait 20 minutes\n",
    "time.sleep(1200) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slovenia\n",
      "lenght: 7\n",
      "Solomon Islands\n",
      "lenght: 4\n",
      "South Africa\n",
      "lenght: 6\n",
      "Spain\n",
      "lenght: 7\n",
      "Sri Lanka\n",
      "lenght: 7\n",
      "Sudan\n",
      "lenght: 6\n",
      "Suriname\n",
      "lenght: 7\n",
      "Swaziland\n",
      "lenght: 6\n",
      "Sweden\n",
      "lenght: 7\n",
      "Switzerland\n",
      "lenght: 7\n",
      "Syrian Arab Republic\n",
      "lenght: 6\n",
      "Tajikistan\n",
      "lenght: 5\n",
      "Thailand\n",
      "lenght: 7\n",
      "The former Yugoslav Republic of Macedonia\n",
      "lenght: 7\n",
      "Timor-Leste\n",
      "lenght: 7\n",
      "Togo\n",
      "lenght: 6\n",
      "Tonga\n",
      "lenght: 7\n",
      "Trinidad and Tobago\n",
      "lenght: 7\n",
      "Tunisia\n",
      "lenght: 7\n",
      "Turkey\n",
      "lenght: 7\n",
      "Turkmenistan\n",
      "lenght: 5\n",
      "Tuvalu\n",
      "lenght: 6\n",
      "Uganda\n",
      "lenght: 7\n",
      "Ukraine\n",
      "lenght: 7\n",
      "United Kingdom\n",
      "lenght: 6\n",
      "United Republic of Tanzania\n",
      "lenght: 6\n",
      "United States of America\n",
      "lenght: 7\n",
      "Uruguay\n",
      "lenght: 6\n",
      "Uzbekistan\n",
      "lenght: 6\n",
      "Vanuatu\n",
      "lenght: 7\n",
      "Venezuela\n",
      "lenght: 7\n",
      "Viet Nam, Socialist Republic of\n",
      "lenght: 6\n",
      "Yemen\n",
      "lenght: 7\n",
      "Zambia\n",
      "lenght: 4\n",
      "Zimbabwe\n",
      "lenght: 5\n",
      "-----finished third block---\n"
     ]
    }
   ],
   "source": [
    "CountryProfiles3 = []\n",
    "\n",
    "for cp in country_profiles[160:240]:\n",
    "    cp_dict = {}\n",
    "    cp_dict['Country'] = cp['Country']\n",
    "    cp_dict['LastModified'] = cp['LastModified']\n",
    "    cp_dict['url'] = cp['DocumentLink']\n",
    "    cp_dict['Content'] = parse_groups(get_groups(get_doc(cp['DocumentLink'])))\n",
    "    print(cp_dict['Country'])\n",
    "    print('lenght:', len(cp_dict['Content']))\n",
    "    \n",
    "    CountryProfiles3.append(cp_dict)\n",
    "    \n",
    "    time.sleep(0.5)\n",
    "    \n",
    "print('-----finished third block---')\n",
    "\n",
    "\n",
    "for i in CountryProfiles3:\n",
    "    i['LastModified'] = i['LastModified'].strftime('%d/%m/%Y')\n",
    "    \n",
    "with open('CountryProfiles3.json', 'w') as fout:\n",
    "    json.dump(CountryProfiles3, fout, indent = 4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CountryProfiles1.json') as json_file:\n",
    "    CountryProfiles1 = json.load(json_file)\n",
    "\n",
    "with open('CountryProfiles2.json') as json_file:\n",
    "    CountryProfiles2 = json.load(json_file)\n",
    "\n",
    "with open('CountryProfiles3.json') as json_file:\n",
    "    CountryProfiles3 = json.load(json_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CountryProfiles = CountryProfiles1 + CountryProfiles2 + CountryProfiles3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CountryProfiles.json', 'w') as fout:\n",
    "    json.dump(CountryProfiles, fout, indent = 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
